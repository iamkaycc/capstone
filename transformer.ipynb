{"cells":[{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1102,"status":"ok","timestamp":1616603118014,"user":{"displayName":"kay cheng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjAk3_0f0XaRCxnyk0ea0us-ai0LRkUIezI4MtsoQ=s64","userId":"00943183185290213830"},"user_tz":-660},"id":"3uuZWcdRt9C9","outputId":"411cbced-d995-4b8d-83d3-cdcee3ee24f8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Tensorflow version: 2.4.1\n"]}],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import os \n","from sklearn.preprocessing import MinMaxScaler\n","import os, datetime\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.models import *\n","from tensorflow.keras.layers import *\n","print('Tensorflow version: {}'.format(tf.__version__))\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22258,"status":"ok","timestamp":1616597539472,"user":{"displayName":"kay cheng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjAk3_0f0XaRCxnyk0ea0us-ai0LRkUIezI4MtsoQ=s64","userId":"00943183185290213830"},"user_tz":-660},"id":"yAoD5QY3uBBh","outputId":"3eb4a4dd-a5fd-4c6b-b76c-f4f754da0d46"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"elapsed":1086,"status":"ok","timestamp":1616602611601,"user":{"displayName":"kay cheng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjAk3_0f0XaRCxnyk0ea0us-ai0LRkUIezI4MtsoQ=s64","userId":"00943183185290213830"},"user_tz":-660},"id":"cR-GJ4WvuNL2","outputId":"bf5942bc-b90d-4f8f-b66c-312fd4c2888d"},"outputs":[{"data":{"text/html":["\u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003eopen\u003c/th\u003e\n","      \u003cth\u003ehigh\u003c/th\u003e\n","      \u003cth\u003elow\u003c/th\u003e\n","      \u003cth\u003eclose\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003e0.93884\u003c/td\u003e\n","      \u003ctd\u003e0.94460\u003c/td\u003e\n","      \u003ctd\u003e0.93813\u003c/td\u003e\n","      \u003ctd\u003e0.93858\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003e0.93874\u003c/td\u003e\n","      \u003ctd\u003e0.94348\u003c/td\u003e\n","      \u003ctd\u003e0.93274\u003c/td\u003e\n","      \u003ctd\u003e0.94002\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003e0.94002\u003c/td\u003e\n","      \u003ctd\u003e0.94273\u003c/td\u003e\n","      \u003ctd\u003e0.93436\u003c/td\u003e\n","      \u003ctd\u003e0.93646\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003e0.93655\u003c/td\u003e\n","      \u003ctd\u003e0.94086\u003c/td\u003e\n","      \u003ctd\u003e0.93297\u003c/td\u003e\n","      \u003ctd\u003e0.93734\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003e0.93734\u003c/td\u003e\n","      \u003ctd\u003e0.94246\u003c/td\u003e\n","      \u003ctd\u003e0.93227\u003c/td\u003e\n","      \u003ctd\u003e0.93980\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e"],"text/plain":["      open     high      low    close\n","0  0.93884  0.94460  0.93813  0.93858\n","1  0.93874  0.94348  0.93274  0.94002\n","2  0.94002  0.94273  0.93436  0.93646\n","3  0.93655  0.94086  0.93297  0.93734\n","4  0.93734  0.94246  0.93227  0.93980"]},"execution_count":22,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["df = pd.read_csv('/content/drive/MyDrive/Data_OANDA_CS24_2021S1/AUD_CAD_D.csv', delimiter=',', usecols=['datetime', 'open', 'high', 'low', 'close'])\n","\n","# Sort DataFrame by date\n","df = df.sort_values('datetime')\n","\n","# Double check the result\n","df.head()\n","df.dropna(how='any', axis=0, inplace=True) # Drop all rows with NaN values\n","df.drop(columns=['datetime'], inplace=True)\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UvRA_qTAvWSg"},"outputs":[],"source":["from sklearn.preprocessing import MinMaxScaler\n","sc = MinMaxScaler(feature_range = (0, 1))\n","training_set_scaled = sc.fit_transform(training_set)\n","testing_set_scaled = sc.fit_transform(testing_set)\n","print(training_set_scaled.shape,testing_set_scaled.shape)"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":255},"executionInfo":{"elapsed":1034,"status":"ok","timestamp":1616602624091,"user":{"displayName":"kay cheng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjAk3_0f0XaRCxnyk0ea0us-ai0LRkUIezI4MtsoQ=s64","userId":"00943183185290213830"},"user_tz":-660},"id":"NJwDpSXcxDpl","outputId":"4b89d3a3-573e-4db7-95b7-a70e48dfa69b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training data shape: (3879, 4)\n","Validation data shape: (485, 4)\n","Test data shape: (484, 4)\n"]},{"data":{"text/html":["\u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003eopen\u003c/th\u003e\n","      \u003cth\u003ehigh\u003c/th\u003e\n","      \u003cth\u003elow\u003c/th\u003e\n","      \u003cth\u003eclose\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003e0.93884\u003c/td\u003e\n","      \u003ctd\u003e0.94460\u003c/td\u003e\n","      \u003ctd\u003e0.93813\u003c/td\u003e\n","      \u003ctd\u003e0.93858\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003e0.93874\u003c/td\u003e\n","      \u003ctd\u003e0.94348\u003c/td\u003e\n","      \u003ctd\u003e0.93274\u003c/td\u003e\n","      \u003ctd\u003e0.94002\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003e0.94002\u003c/td\u003e\n","      \u003ctd\u003e0.94273\u003c/td\u003e\n","      \u003ctd\u003e0.93436\u003c/td\u003e\n","      \u003ctd\u003e0.93646\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003e0.93655\u003c/td\u003e\n","      \u003ctd\u003e0.94086\u003c/td\u003e\n","      \u003ctd\u003e0.93297\u003c/td\u003e\n","      \u003ctd\u003e0.93734\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003e0.93734\u003c/td\u003e\n","      \u003ctd\u003e0.94246\u003c/td\u003e\n","      \u003ctd\u003e0.93227\u003c/td\u003e\n","      \u003ctd\u003e0.93980\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e"],"text/plain":["      open     high      low    close\n","0  0.93884  0.94460  0.93813  0.93858\n","1  0.93874  0.94348  0.93274  0.94002\n","2  0.94002  0.94273  0.93436  0.93646\n","3  0.93655  0.94086  0.93297  0.93734\n","4  0.93734  0.94246  0.93227  0.93980"]},"execution_count":23,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["times = sorted(df.index.values)\n","last_10pct = sorted(df.index.values)[-int(0.1*len(times))] # Last 10% of series\n","last_20pct = sorted(df.index.values)[-int(0.2*len(times))] # Last 20% of series\n","\n","df_train = df[(df.index \u003c last_20pct)]  # Training data are 80% of total data\n","df_val = df[(df.index \u003e= last_20pct) \u0026 (df.index \u003c last_10pct)]\n","df_test = df[(df.index \u003e= last_10pct)]\n","\n","# Remove date column\n","# df_train.drop(columns=['datetime'], inplace=True)\n","# df_val.drop(columns=['datetime'], inplace=True)\n","# df_test.drop(columns=['datetime'], inplace=True)\n","\n","# Convert pandas columns into arrays\n","train_data = df_train.values\n","val_data = df_val.values\n","test_data = df_test.values\n","print('Training data shape: {}'.format(train_data.shape))\n","print('Validation data shape: {}'.format(val_data.shape))\n","print('Test data shape: {}'.format(test_data.shape))\n","\n","df_train.head()"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1118,"status":"ok","timestamp":1616602685538,"user":{"displayName":"kay cheng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjAk3_0f0XaRCxnyk0ea0us-ai0LRkUIezI4MtsoQ=s64","userId":"00943183185290213830"},"user_tz":-660},"id":"woFKXS-H_oWL","outputId":"1c89174f-e3dd-45b7-f2ad-1ec55f9ea369"},"outputs":[{"name":"stdout","output_type":"stream","text":["(3879, 4) (484, 4) (485, 4)\n"]}],"source":["#normalization\n","from sklearn.preprocessing import MinMaxScaler\n","sc = MinMaxScaler(feature_range = (0, 1))\n","train_data = sc.fit_transform(train_data)\n","test_data = sc.fit_transform(test_data)\n","val_data = sc.fit_transform(val_data)\n","print(train_data.shape,test_data.shape,val_data.shape)\n"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":959,"status":"ok","timestamp":1616603122477,"user":{"displayName":"kay cheng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjAk3_0f0XaRCxnyk0ea0us-ai0LRkUIezI4MtsoQ=s64","userId":"00943183185290213830"},"user_tz":-660},"id":"gJ2iOi7fCVBK","outputId":"b7247a87-33ac-4539-ba97-d0ca4010070c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training set shape (3751, 128, 4) (3751,)\n","Validation set shape (357, 128, 4) (357,)\n","Testing set shape (356, 128, 4) (356,)\n"]}],"source":["# Training data\n","seq_len = 128\n","X_train, y_train = [], []\n","for i in range(seq_len, len(train_data)):\n","  X_train.append(train_data[i-seq_len:i]) # Chunks of training data with a length of 128 df-rows\n","  y_train.append(train_data[:, 3][i]) #Value of 4th column (Close Price) of df-row 128+1\n","X_train, y_train = np.array(X_train), np.array(y_train)\n","\n","###############################################################################\n","\n","# Validation data\n","X_val, y_val = [], []\n","for i in range(seq_len, len(val_data)):\n","    X_val.append(val_data[i-seq_len:i])\n","    y_val.append(val_data[:, 3][i])\n","X_val, y_val = np.array(X_val), np.array(y_val)\n","\n","###############################################################################\n","\n","# Test data\n","X_test, y_test = [], []\n","for i in range(seq_len, len(test_data)):\n","    X_test.append(test_data[i-seq_len:i])\n","    y_test.append(test_data[:, 3][i])    \n","X_test, y_test = np.array(X_test), np.array(y_test)\n","\n","print('Training set shape', X_train.shape, y_train.shape)\n","print('Validation set shape', X_val.shape, y_val.shape)\n","print('Testing set shape' ,X_test.shape, y_test.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"XuomHk8REuV7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_6\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_7 (InputLayer)            [(None, 128, 4)]     0                                            \n","__________________________________________________________________________________________________\n","time2_vector_8 (Time2Vector)    (None, 128, 2)       512         input_7[0][0]                    \n","__________________________________________________________________________________________________\n","concatenate_6 (Concatenate)     (None, 128, 6)       0           input_7[0][0]                    \n","                                                                 time2_vector_8[0][0]             \n","__________________________________________________________________________________________________\n","transformer_encoder_18 (Transfo (None, 128, 6)       86308       concatenate_6[0][0]              \n","                                                                 concatenate_6[0][0]              \n","                                                                 concatenate_6[0][0]              \n","__________________________________________________________________________________________________\n","transformer_encoder_19 (Transfo (None, 128, 6)       86308       transformer_encoder_18[0][0]     \n","                                                                 transformer_encoder_18[0][0]     \n","                                                                 transformer_encoder_18[0][0]     \n","__________________________________________________________________________________________________\n","transformer_encoder_20 (Transfo (None, 128, 6)       86308       transformer_encoder_19[0][0]     \n","                                                                 transformer_encoder_19[0][0]     \n","                                                                 transformer_encoder_19[0][0]     \n","__________________________________________________________________________________________________\n","global_average_pooling1d_6 (Glo (None, 128)          0           transformer_encoder_20[0][0]     \n","__________________________________________________________________________________________________\n","dropout_12 (Dropout)            (None, 128)          0           global_average_pooling1d_6[0][0] \n","__________________________________________________________________________________________________\n","dense_12 (Dense)                (None, 64)           8256        dropout_12[0][0]                 \n","__________________________________________________________________________________________________\n","dropout_13 (Dropout)            (None, 64)           0           dense_12[0][0]                   \n","__________________________________________________________________________________________________\n","dense_13 (Dense)                (None, 1)            65          dropout_13[0][0]                 \n","==================================================================================================\n","Total params: 267,757\n","Trainable params: 267,757\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","Epoch 1/35\n","118/118 [==============================] - 383s 3s/step - loss: 0.1488 - mae: 0.2864 - mape: 121850.1639 - val_loss: 0.0227 - val_mae: 0.1172 - val_mape: 1272382.2500\n","\n","Epoch 00001: val_loss improved from inf to 0.02269, saving model to Transformer+TimeEmbedding.hdf5\n","Epoch 2/35\n","118/118 [==============================] - 335s 3s/step - loss: 0.0086 - mae: 0.0724 - mape: 74079.1123 - val_loss: 0.0225 - val_mae: 0.1226 - val_mape: 733887.7500\n","\n","Epoch 00002: val_loss improved from 0.02269 to 0.02255, saving model to Transformer+TimeEmbedding.hdf5\n","Epoch 3/35\n","118/118 [==============================] - 340s 3s/step - loss: 0.0060 - mae: 0.0610 - mape: 51074.1045 - val_loss: 0.0239 - val_mae: 0.1288 - val_mape: 703027.2500\n","\n","Epoch 00003: val_loss did not improve from 0.02255\n","Epoch 4/35\n","118/118 [==============================] - 347s 3s/step - loss: 0.0051 - mae: 0.0569 - mape: 122843.2696 - val_loss: 0.0135 - val_mae: 0.0921 - val_mape: 494175.6875\n","\n","Epoch 00004: val_loss improved from 0.02255 to 0.01348, saving model to Transformer+TimeEmbedding.hdf5\n","Epoch 5/35\n","118/118 [==============================] - 333s 3s/step - loss: 0.0046 - mae: 0.0533 - mape: 54453.4519 - val_loss: 0.0125 - val_mae: 0.0898 - val_mape: 578234.5625\n","\n","Epoch 00005: val_loss improved from 0.01348 to 0.01250, saving model to Transformer+TimeEmbedding.hdf5\n","Epoch 6/35\n","118/118 [==============================] - 330s 3s/step - loss: 0.0047 - mae: 0.0541 - mape: 47595.3355 - val_loss: 0.0084 - val_mae: 0.0718 - val_mape: 519209.5312\n","\n","Epoch 00006: val_loss improved from 0.01250 to 0.00845, saving model to Transformer+TimeEmbedding.hdf5\n","Epoch 7/35\n","118/118 [==============================] - 327s 3s/step - loss: 0.0041 - mae: 0.0506 - mape: 41250.5200 - val_loss: 0.0089 - val_mae: 0.0751 - val_mape: 471159.1562\n","\n","Epoch 00007: val_loss did not improve from 0.00845\n","Epoch 8/35\n","118/118 [==============================] - 328s 3s/step - loss: 0.0041 - mae: 0.0507 - mape: 18807.7905 - val_loss: 0.0080 - val_mae: 0.0686 - val_mape: 426613.2500\n","\n","Epoch 00008: val_loss improved from 0.00845 to 0.00803, saving model to Transformer+TimeEmbedding.hdf5\n","Epoch 9/35\n","118/118 [==============================] - 329s 3s/step - loss: 0.0038 - mae: 0.0486 - mape: 27133.6416 - val_loss: 0.0082 - val_mae: 0.0719 - val_mape: 444114.7812\n","\n","Epoch 00009: val_loss did not improve from 0.00803\n","Epoch 10/35\n","118/118 [==============================] - 328s 3s/step - loss: 0.0034 - mae: 0.0456 - mape: 31544.4393 - val_loss: 0.0066 - val_mae: 0.0645 - val_mape: 481639.0000\n","\n","Epoch 00010: val_loss improved from 0.00803 to 0.00662, saving model to Transformer+TimeEmbedding.hdf5\n","Epoch 11/35\n","118/118 [==============================] - 328s 3s/step - loss: 0.0035 - mae: 0.0468 - mape: 31813.4980 - val_loss: 0.0076 - val_mae: 0.0685 - val_mape: 361616.3438\n","\n","Epoch 00011: val_loss did not improve from 0.00662\n","Epoch 12/35\n","118/118 [==============================] - 330s 3s/step - loss: 0.0033 - mae: 0.0453 - mape: 186972.9800 - val_loss: 0.0078 - val_mae: 0.0708 - val_mape: 383999.4062\n","\n","Epoch 00012: val_loss did not improve from 0.00662\n","Epoch 13/35\n","118/118 [==============================] - 329s 3s/step - loss: 0.0029 - mae: 0.0426 - mape: 47101.9726 - val_loss: 0.0077 - val_mae: 0.0712 - val_mape: 358391.7188\n","\n","Epoch 00013: val_loss did not improve from 0.00662\n","Epoch 14/35\n","118/118 [==============================] - 329s 3s/step - loss: 0.0031 - mae: 0.0433 - mape: 20199.2756 - val_loss: 0.0089 - val_mae: 0.0768 - val_mape: 379435.8438\n","\n","Epoch 00014: val_loss did not improve from 0.00662\n","Epoch 15/35\n","118/118 [==============================] - 329s 3s/step - loss: 0.0031 - mae: 0.0433 - mape: 17028.0802 - val_loss: 0.0074 - val_mae: 0.0704 - val_mape: 366755.6250\n","\n","Epoch 00015: val_loss did not improve from 0.00662\n","Epoch 16/35\n","118/118 [==============================] - 342s 3s/step - loss: 0.0028 - mae: 0.0415 - mape: 100076.1752 - val_loss: 0.0070 - val_mae: 0.0680 - val_mape: 438533.5938\n","\n","Epoch 00016: val_loss did not improve from 0.00662\n","Epoch 17/35\n","118/118 [==============================] - 342s 3s/step - loss: 0.0028 - mae: 0.0416 - mape: 185193.4509 - val_loss: 0.0066 - val_mae: 0.0637 - val_mape: 353358.6250\n","\n","Epoch 00017: val_loss did not improve from 0.00662\n","Epoch 18/35\n","118/118 [==============================] - 338s 3s/step - loss: 0.0027 - mae: 0.0406 - mape: 112913.7483 - val_loss: 0.0072 - val_mae: 0.0664 - val_mape: 325326.3125\n","\n","Epoch 00018: val_loss did not improve from 0.00662\n","Epoch 19/35\n","118/118 [==============================] - 339s 3s/step - loss: 0.0027 - mae: 0.0407 - mape: 39830.7792 - val_loss: 0.0066 - val_mae: 0.0618 - val_mape: 320443.4688\n","\n","Epoch 00019: val_loss did not improve from 0.00662\n","Epoch 20/35\n","118/118 [==============================] - 337s 3s/step - loss: 0.0032 - mae: 0.0449 - mape: 19393.8422 - val_loss: 0.0077 - val_mae: 0.0672 - val_mape: 269882.8125\n","\n","Epoch 00020: val_loss did not improve from 0.00662\n","Epoch 21/35\n","118/118 [==============================] - 334s 3s/step - loss: 0.0026 - mae: 0.0394 - mape: 250825.6635 - val_loss: 0.0056 - val_mae: 0.0589 - val_mape: 420719.6562\n","\n","Epoch 00021: val_loss improved from 0.00662 to 0.00561, saving model to Transformer+TimeEmbedding.hdf5\n","Epoch 22/35\n","118/118 [==============================] - 331s 3s/step - loss: 0.0023 - mae: 0.0375 - mape: 84765.9281 - val_loss: 0.0068 - val_mae: 0.0652 - val_mape: 334088.5000\n","\n","Epoch 00022: val_loss did not improve from 0.00561\n","Epoch 23/35\n","118/118 [==============================] - 331s 3s/step - loss: 0.0025 - mae: 0.0387 - mape: 9032.3778 - val_loss: 0.0095 - val_mae: 0.0805 - val_mape: 425531.1250\n","\n","Epoch 00023: val_loss did not improve from 0.00561\n","Epoch 24/35\n","118/118 [==============================] - 333s 3s/step - loss: 0.0026 - mae: 0.0401 - mape: 90865.2565 - val_loss: 0.0068 - val_mae: 0.0659 - val_mape: 374205.4375\n","\n","Epoch 00024: val_loss did not improve from 0.00561\n","Epoch 25/35\n","118/118 [==============================] - 333s 3s/step - loss: 0.0023 - mae: 0.0374 - mape: 6916.5697 - val_loss: 0.0078 - val_mae: 0.0721 - val_mape: 380762.1250\n","\n","Epoch 00025: val_loss did not improve from 0.00561\n","Epoch 26/35\n","118/118 [==============================] - 333s 3s/step - loss: 0.0022 - mae: 0.0373 - mape: 50841.3906 - val_loss: 0.0072 - val_mae: 0.0688 - val_mape: 368278.0625\n","\n","Epoch 00026: val_loss did not improve from 0.00561\n","Epoch 27/35\n","118/118 [==============================] - 335s 3s/step - loss: 0.0024 - mae: 0.0393 - mape: 7913.3402 - val_loss: 0.0082 - val_mae: 0.0741 - val_mape: 373657.6562\n","\n","Epoch 00027: val_loss did not improve from 0.00561\n","Epoch 28/35\n","118/118 [==============================] - 333s 3s/step - loss: 0.0023 - mae: 0.0371 - mape: 18407.8680 - val_loss: 0.0079 - val_mae: 0.0726 - val_mape: 390782.4688\n","\n","Epoch 00028: val_loss did not improve from 0.00561\n","Epoch 29/35\n","118/118 [==============================] - 331s 3s/step - loss: 0.0023 - mae: 0.0378 - mape: 127599.2964 - val_loss: 0.0073 - val_mae: 0.0673 - val_mape: 309264.2500\n","\n","Epoch 00029: val_loss did not improve from 0.00561\n","Epoch 30/35\n","118/118 [==============================] - 329s 3s/step - loss: 0.0024 - mae: 0.0383 - mape: 47010.7102 - val_loss: 0.0084 - val_mae: 0.0752 - val_mape: 508097.5625\n","\n","Epoch 00030: val_loss did not improve from 0.00561\n","Epoch 31/35\n","118/118 [==============================] - 333s 3s/step - loss: 0.0021 - mae: 0.0355 - mape: 33791.0554 - val_loss: 0.0061 - val_mae: 0.0611 - val_mape: 391538.4062\n","\n","Epoch 00031: val_loss did not improve from 0.00561\n","Epoch 32/35\n","118/118 [==============================] - 331s 3s/step - loss: 0.0020 - mae: 0.0348 - mape: 59996.8500 - val_loss: 0.0067 - val_mae: 0.0659 - val_mape: 394114.8125\n","\n","Epoch 00032: val_loss did not improve from 0.00561\n","Epoch 33/35\n","118/118 [==============================] - 322s 3s/step - loss: 0.0018 - mae: 0.0337 - mape: 51010.6360 - val_loss: 0.0075 - val_mae: 0.0701 - val_mape: 492546.5000\n","\n","Epoch 00033: val_loss did not improve from 0.00561\n","Epoch 34/35\n","118/118 [==============================] - 321s 3s/step - loss: 0.0019 - mae: 0.0346 - mape: 21405.5050 - val_loss: 0.0063 - val_mae: 0.0629 - val_mape: 415896.7812\n","\n","Epoch 00034: val_loss did not improve from 0.00561\n","Epoch 35/35\n","118/118 [==============================] - 324s 3s/step - loss: 0.0019 - mae: 0.0338 - mape: 2537.2279 - val_loss: 0.0079 - val_mae: 0.0716 - val_mape: 350408.8750\n","\n","Epoch 00035: val_loss did not improve from 0.00561\n"]}],"source":["model = create_model()\n","model.summary()\n","\n","callback = tf.keras.callbacks.ModelCheckpoint('Transformer+TimeEmbedding.hdf5', \n","                                              monitor='val_loss', \n","                                              save_best_only=True, verbose=1)\n","batch_size = 32\n","history = model.fit(X_train, y_train, \n","                    batch_size=batch_size, \n","                    epochs=35, \n","                    callbacks=[callback],\n","                    validation_data=(X_val, y_val))  \n","\n","model = tf.keras.models.load_model('/content/Transformer+TimeEmbedding.hdf5',\n","                                   custom_objects={'Time2Vector': Time2Vector, \n","                                                   'SingleAttention': SingleAttention,\n","                                                   'MultiAttention': MultiAttention,\n","                                                   'TransformerEncoder': TransformerEncoder})"]},{"cell_type":"code","execution_count":36,"metadata":{"executionInfo":{"elapsed":946,"status":"ok","timestamp":1616603128705,"user":{"displayName":"kay cheng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjAk3_0f0XaRCxnyk0ea0us-ai0LRkUIezI4MtsoQ=s64","userId":"00943183185290213830"},"user_tz":-660},"id":"wAS9dAFqCq6Q"},"outputs":[],"source":["class Time2Vector(Layer):\n","  def __init__(self, seq_len, **kwargs):\n","    super(Time2Vector, self).__init__()\n","    self.seq_len = seq_len\n","\n","  def build(self, input_shape):\n","    '''Initialize weights and biases with shape (batch, seq_len)'''\n","    self.weights_linear = self.add_weight(name='weight_linear',\n","                                shape=(int(self.seq_len),),\n","                                initializer='uniform',\n","                                trainable=True)\n","    \n","    self.bias_linear = self.add_weight(name='bias_linear',\n","                                shape=(int(self.seq_len),),\n","                                initializer='uniform',\n","                                trainable=True)\n","    \n","    self.weights_periodic = self.add_weight(name='weight_periodic',\n","                                shape=(int(self.seq_len),),\n","                                initializer='uniform',\n","                                trainable=True)\n","\n","    self.bias_periodic = self.add_weight(name='bias_periodic',\n","                                shape=(int(self.seq_len),),\n","                                initializer='uniform',\n","                                trainable=True)\n","\n","  def call(self, x):\n","    '''Calculate linear and periodic time features'''\n","    x = tf.math.reduce_mean(x[:,:,:4], axis=-1) \n","    time_linear = self.weights_linear * x + self.bias_linear # Linear time feature\n","    time_linear = tf.expand_dims(time_linear, axis=-1) # Add dimension (batch, seq_len, 1)\n","    \n","    time_periodic = tf.math.sin(tf.multiply(x, self.weights_periodic) + self.bias_periodic)\n","    time_periodic = tf.expand_dims(time_periodic, axis=-1) # Add dimension (batch, seq_len, 1)\n","    return tf.concat([time_linear, time_periodic], axis=-1) # shape = (batch, seq_len, 2)\n","   \n","  def get_config(self): # Needed for saving and loading model with custom layer\n","    config = super().get_config().copy()\n","    config.update({'seq_len': self.seq_len})\n","    return config"]},{"cell_type":"code","execution_count":37,"metadata":{"executionInfo":{"elapsed":1501,"status":"ok","timestamp":1616603191020,"user":{"displayName":"kay cheng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjAk3_0f0XaRCxnyk0ea0us-ai0LRkUIezI4MtsoQ=s64","userId":"00943183185290213830"},"user_tz":-660},"id":"mR5PWAaGCxQz"},"outputs":[],"source":["class SingleAttention(Layer):\n","  def __init__(self, d_k, d_v):\n","    super(SingleAttention, self).__init__()\n","    self.d_k = d_k\n","    self.d_v = d_v\n","\n","  def build(self, input_shape):\n","    self.query = Dense(self.d_k, \n","                       input_shape=input_shape, \n","                       kernel_initializer='glorot_uniform', \n","                       bias_initializer='glorot_uniform')\n","    \n","    self.key = Dense(self.d_k, \n","                     input_shape=input_shape, \n","                     kernel_initializer='glorot_uniform', \n","                     bias_initializer='glorot_uniform')\n","    \n","    self.value = Dense(self.d_v, \n","                       input_shape=input_shape, \n","                       kernel_initializer='glorot_uniform', \n","                       bias_initializer='glorot_uniform')\n","\n","  def call(self, inputs): # inputs = (in_seq, in_seq, in_seq)\n","    q = self.query(inputs[0])\n","    k = self.key(inputs[1])\n","\n","    attn_weights = tf.matmul(q, k, transpose_b=True)\n","    attn_weights = tf.map_fn(lambda x: x/np.sqrt(self.d_k), attn_weights)\n","    attn_weights = tf.nn.softmax(attn_weights, axis=-1)\n","    \n","    v = self.value(inputs[2])\n","    attn_out = tf.matmul(attn_weights, v)\n","    return attn_out    \n","#############################################################################\n","\n","class MultiAttention(Layer):\n","  def __init__(self, d_k, d_v, n_heads):\n","    super(MultiAttention, self).__init__()\n","    self.d_k = d_k\n","    self.d_v = d_v\n","    self.n_heads = n_heads\n","    self.attn_heads = list()\n","\n","  def build(self, input_shape):\n","    for n in range(self.n_heads):\n","      self.attn_heads.append(SingleAttention(self.d_k, self.d_v))  \n","    \n","    # input_shape[0]=(batch, seq_len, 7), input_shape[0][-1]=7 \n","    self.linear = Dense(input_shape[0][-1], \n","                        input_shape=input_shape, \n","                        kernel_initializer='glorot_uniform', \n","                        bias_initializer='glorot_uniform')\n","\n","  def call(self, inputs):\n","    attn = [self.attn_heads[i](inputs) for i in range(self.n_heads)]\n","    concat_attn = tf.concat(attn, axis=-1)\n","    multi_linear = self.linear(concat_attn)\n","    return multi_linear\n","#############################################################################\n","\n","class TransformerEncoder(Layer):\n","  def __init__(self, d_k, d_v, n_heads, ff_dim, dropout=0.1, **kwargs):\n","    super(TransformerEncoder, self).__init__()\n","    self.d_k = d_k\n","    self.d_v = d_v\n","    self.n_heads = n_heads\n","    self.ff_dim = ff_dim\n","    self.attn_heads = list()\n","    self.dropout_rate = dropout\n","\n","  def build(self, input_shape):\n","    self.attn_multi = MultiAttention(self.d_k, self.d_v, self.n_heads)\n","    self.attn_dropout = Dropout(self.dropout_rate)\n","    self.attn_normalize = LayerNormalization(input_shape=input_shape, epsilon=1e-6)\n","\n","    self.ff_conv1D_1 = Conv1D(filters=self.ff_dim, kernel_size=1, activation='relu')\n","    # input_shape[0]=(batch, seq_len, 7), input_shape[0][-1] = 7 \n","    self.ff_conv1D_2 = Conv1D(filters=input_shape[0][-1], kernel_size=1) \n","    self.ff_dropout = Dropout(self.dropout_rate)\n","    self.ff_normalize = LayerNormalization(input_shape=input_shape, epsilon=1e-6)    \n","  \n","  def call(self, inputs): # inputs = (in_seq, in_seq, in_seq)\n","    attn_layer = self.attn_multi(inputs)\n","    attn_layer = self.attn_dropout(attn_layer)\n","    attn_layer = self.attn_normalize(inputs[0] + attn_layer)\n","\n","    ff_layer = self.ff_conv1D_1(attn_layer)\n","    ff_layer = self.ff_conv1D_2(ff_layer)\n","    ff_layer = self.ff_dropout(ff_layer)\n","    ff_layer = self.ff_normalize(inputs[0] + ff_layer)\n","    return ff_layer \n","\n","  def get_config(self): # Needed for saving and loading model with custom layer\n","    config = super().get_config().copy()\n","    config.update({'d_k': self.d_k,\n","                   'd_v': self.d_v,\n","                   'n_heads': self.n_heads,\n","                   'ff_dim': self.ff_dim,\n","                   'attn_heads': self.attn_heads,\n","                   'dropout_rate': self.dropout_rate})\n","    return config"]},{"cell_type":"code","execution_count":47,"metadata":{"executionInfo":{"elapsed":1010,"status":"ok","timestamp":1616603687526,"user":{"displayName":"kay cheng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjAk3_0f0XaRCxnyk0ea0us-ai0LRkUIezI4MtsoQ=s64","userId":"00943183185290213830"},"user_tz":-660},"id":"T24NeZ5mDy4M"},"outputs":[],"source":["def create_model():\n","  '''Initialize time and transformer layers'''\n","  d_k = 256\n","  d_v = 256\n","  n_heads = 12\n","  ff_dim = 256\n","  batch_size = 32\n","  time_embedding = Time2Vector(seq_len)\n","  attn_layer1 = TransformerEncoder(d_k, d_v, n_heads, ff_dim)\n","  attn_layer2 = TransformerEncoder(d_k, d_v, n_heads, ff_dim)\n","  attn_layer3 = TransformerEncoder(d_k, d_v, n_heads, ff_dim)\n","\n","  '''Construct model'''\n","  in_seq = Input(shape=(seq_len, 4))\n","  x = time_embedding(in_seq)\n","  x = Concatenate(axis=-1)([in_seq, x])\n","  x = attn_layer1((x, x, x))\n","  x = attn_layer2((x, x, x))\n","  x = attn_layer3((x, x, x))\n","  x = GlobalAveragePooling1D(data_format='channels_first')(x)\n","  x = Dropout(0.1)(x)\n","  x = Dense(64, activation='relu')(x)\n","  x = Dropout(0.1)(x)\n","  out = Dense(1, activation='linear')(x)\n","\n","  model = Model(inputs=in_seq, outputs=out)\n","  model.compile(loss='mse', optimizer='adam', metrics=['mae', 'mape'])\n","  return model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eo8vqNZhEjZe"},"outputs":[],"source":[""]}],"metadata":{"colab":{"authorship_tag":"ABX9TyM7uPurlQPtB6Ov4weJ6TK8","name":"transformer.ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}